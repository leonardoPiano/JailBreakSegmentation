{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dbcfa42-40df-4a40-85e6-e97f1b99308a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gliner import GLiNER \n",
    "model=\"../train/models/new_synth_binary_v2/checkpoint-3000\"\n",
    "trained_model=GLiNER.from_pretrained(model,device=\"cuda:0\")\n",
    "trained_model=trained_model.to(\"cuda:0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acfac948-4c58-4b8e-88b7-1516782b8098",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "import pandas as pd\n",
    "mt_bench = load_dataset(\"philschmid/mt-bench\")\n",
    "mt_questions=[x[0] for x in mt_bench[\"train\"][\"turns\"]]\n",
    "benign_uap=pd.read_json(\"dataset_for_gpt_benign_uap_structure.jsonl\",lines=True)\n",
    "benign_questions=[x[1][\"content\"] for x in benign_uap[\"messages\"]]\n",
    "xstest=pd.read_csv(\"xstest_v2_prompts.csv\")[\"prompt\"].unique().tolist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "d03450d6-5133-4d14-9e21-6546f257851e",
   "metadata": {},
   "outputs": [],
   "source": [
    "safe_categories=[\"homonyms\",\"figurative_language\",\"safe_targets\",\"safe_contexts\",\"definitions\",\"nons_group_real_discr\",\"real_group_nons_discr\",\n",
    "                   \"historical_events\",\"privacy_public\",\"privacy_fictional\"]\n",
    "\n",
    "xstest=pd.read_csv(\"xstest_v2_prompts.csv\")\n",
    "xstest_safe=xstest[xstest[\"type\"].isin(safe_categories)]\n",
    "xstest_safe_prompts=xstest_safe[\"prompt\"].unique().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "fcc9eced-f745-49a2-a01a-c860df6a57f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(xstest_safe[\"type\"].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "8f1ba958-3ff5-40fd-9ff6-62bbca18c00d",
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets={\"MT\":mt_questions,\"Benign\":benign_questions,\"XSTEST\":xstest_safe_prompts}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "1b70f2c6-dbe0-4384-84d2-99a3b13d81a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "def compute_rejection_rate(data):\n",
    "    output=[]\n",
    "    for item in tqdm(data):\n",
    "        question=item     \n",
    "        answers=trained_model.predict_entities(question,labels=[\"malicious goal\",\"benign goal\"],flat_ner=True,multi_label=False,threshold=0.10)\n",
    "      \n",
    "        if len(answers)>0:\n",
    "            best=np.argmax([x[\"score\"] for x in answers])\n",
    "            best_answer=answers[best]\n",
    "            output.append({\"span\":best_answer[\"text\"],\"label\":best_answer[\"label\"]})\n",
    "    \n",
    "    rejected=[x for x in output if \"malicious\" in x[\"label\"]]\n",
    "    \n",
    "   \n",
    "    reject_rate=(len(rejected)/ len(data)) *100\n",
    "    print(f\"Rejection Rate: \",reject_rate)\n",
    "    return rejected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a7c3b11-9511-4890-806f-bf58c69bcb9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "res={}\n",
    "for name,data in datasets.items(): \n",
    "    print(\"Dataset\",name)\n",
    "    res[name]=compute_rejection_rate(data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03eebc3c-447b-4a4c-aef8-20fdee834909",
   "metadata": {},
   "source": [
    "## BASELINES"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfabc2ab-9c8b-4778-aa62-b7fac231ee6e",
   "metadata": {},
   "source": [
    "#### PROMPT GUARD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55d24b5c-b3d7-4626-95cc-d2ee3f0e2d67",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "classifier = pipeline(\"text-classification\", model=\"meta-llama/Llama-Prompt-Guard-2-86M\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eb80ae6-8bb9-4056-9c73-aaf88342ee30",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "def compute_rejection_rate(data):    \n",
    "    output=[]\n",
    "    for item in tqdm(data):\n",
    "        question=item       \n",
    "        label=classifier(question)[0][\"label\"]            \n",
    "        output.append(label)        \n",
    "    rejected=[x for x in output if \"LABEL_1\"==x]    \n",
    "    reject_rate=(len(rejected)/ len(data)) *100\n",
    "    print(f\"Rejection Rate: \",reject_rate)\n",
    "    return rejected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eb420b4-d318-437c-a4ce-d989edc57aac",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_guard_res={}\n",
    "for name,data in datasets.items():\n",
    "    print(\"Dataset\",name)\n",
    "    prompt_guard_res[name]=compute_rejection_rate(data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc44d1fc-a740-4018-81fd-377209ed7a68",
   "metadata": {},
   "source": [
    "### LLAMA GUARD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1984ca4-f624-41ec-9ca7-d4d89c0df6a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv(dotenv_path=\"../.env\")\n",
    "\n",
    "HF_TOKEN=os.environ.get(\"HF_TOKEN\")\n",
    "os.environ[\"HF_TOKEN\"] = HF_TOKEN\n",
    "os.environ[\"HUGGINFACEHUB_API_TOKEN\"] = HF_TOKEN\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = \"0\"\n",
    "from transformers import AutoConfig, AutoTokenizer,AutoModelForCausalLM\n",
    "import torch\n",
    "from vllm import LLM, SamplingParams\n",
    "model_id = \"meta-llama/Llama-Guard-3-8B\"\n",
    "dtype = torch.bfloat16\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id, use_auth_token=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "499e1e02-dfa2-4fe3-9696-b7e5ebeab1f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm =LLM(model=model_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "579ac5d8-9629-4ebd-8a86-adc6438f3315",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "sampling_params = SamplingParams(temperature=0.00, top_p=1, max_tokens=25)\n",
    "def compute_rejection_rate(data):   \n",
    "    output=[]                        \n",
    "    messages=[[{\"role\": \"user\", \"content\": x}] for x in data]\n",
    "    outputs = llm.chat(messages, sampling_params)\n",
    "    for i, answer in enumerate(outputs):\n",
    "        generated_text = answer.outputs[0].text\n",
    "        prompt = data[i]\n",
    "        output.append({\"prompt\": prompt, \"label\": generated_text})\n",
    "\n",
    "    rejected=[x for x in output if \"unsafe\" in x[\"label\"]]     \n",
    "         \n",
    "    reject_rate=(len(rejected)/ len(data)) *100\n",
    "    print(f\"Rejection Rate: \",reject_rate)\n",
    "    \n",
    "    return rejected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db66c1b5-20e1-414b-bea7-e560e806cd15",
   "metadata": {},
   "outputs": [],
   "source": [
    "llama_guard_res={}\n",
    "for name,data in datasets.items():\n",
    "    print(\"Dataset\",name)    \n",
    "    llama_guard_res[name]=compute_rejection_rate(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61df5d77-741f-488d-82aa-c535c7d4c43c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
